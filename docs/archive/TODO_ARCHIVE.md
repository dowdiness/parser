# TODO Archive

Moved from previous TODO.md for context retention. Includes completed work logs, historical decisions, and detailed per-task notes.

---

# Incremental Parser Refactoring TODO

**Last Updated:** 2026-02-01
**Status:** âœ… All Core Priorities Complete + ROADMAP Phase 0 Complete

---

## ðŸ“Š **Progress Overview**

```
Priority 0: Truth & Documentation    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (5/5 complete) âœ…
Priority 1: Remove Dead Code         [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (2/2 complete) âœ…
Priority 2: Fix Duplication          [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (1/1 complete) âœ…
Priority 3: Performance              [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (2/2 complete) âœ…
Priority 4: Future Enhancements      [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]   0% (0/2 optional)

Overall Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (10/10 core tasks) ðŸŽ‰
```

---

## ðŸŽ¯ **Priority 0: Truth & Documentation** (Week 1, Days 1-2)

**Goal:** Align documentation with reality based on Lezer research

### âœ… Task 0.0: Create TODO.md
- [x] Create this tracking document
- **Status:** âœ… Complete
- **Files:** `parser/TODO.md`

### âœ… Task 0.1: Update STRUCTURAL_VALIDATION.md
- [x] Remove claims about "Lezer-style 3 strategies"
- [x] Explain what we actually learned from Lezer
- [x] Document why GLR approach doesn't apply to recursive descent
- [x] Clarify that cache invalidation is the real optimization
- **Status:** âœ… Complete (2026-01-04)
- **Files:** `parser/docs/STRUCTURAL_VALIDATION.md`
- **Time Taken:** 1.5 hours

**Changes made:**
- Completely rewrote to explain Wagner-Graham + cache approach
- Added detailed Lezer research findings section
- Explained why we can't implement Lezer's algorithm
- Documented "3 strategies" misconception honestly
- Added comparison table and future enhancements section

### âœ… Task 0.2: Update LEZER_IMPLEMENTATION.md
- [x] Clarify what Lezer actually does (position-based fragment reuse with LR states)
- [x] Explain why we can't directly implement Lezer's approach
- [x] Document what we borrowed (cache invalidation concept)
- [x] Remove misleading "Lezer-style" claims
- **Status:** âœ… Complete (2026-01-04)
- **Files:** `parser/docs/LEZER_IMPLEMENTATION.md`
- **Time Taken:** 2 hours

**Changes made:**
- Added detailed analysis of actual Lezer source code
- Explained FragmentCursor, state-based validation, granular reuse
- Clear separation: what we borrowed vs what we can't borrow
- Documented why "3 strategies" were project-specific
- Added code examples from actual Lezer implementation

### âœ… Task 0.3: Update IMPLEMENTATION_COMPLETE.md
- [x] Change title to "Incremental Parser - Implementation Status"
- [x] Document actual implementation: Wagner-Graham + cache
- [x] Remove false claims about validation-based reuse
- [x] Add "What Changed" section explaining documentation update
- **Status:** âœ… Complete (2026-01-04)
- **Files:** `parser/docs/IMPLEMENTATION_COMPLETE.md`
- **Time Taken:** 2 hours

**Changes made:**
- Renamed from "Lezer-style Complete" to honest status assessment
- Clear sections: What IS implemented vs What is NOT
- Added "What Changed (2026-01-04)" section documenting updates
- Honest comparison with Lezer (what we learned)
- Production-ready assessment based on actual capabilities

### âœ… Task 0.4: Update incremental_parser.mbt comments
- [x] Update file header comments
- [x] Change "Lezer-style incremental repair" comments
- [x] Document actual algorithm clearly
- [x] Add references to actual sources (not misattributed)
- **Status:** âœ… Complete (2026-01-04)
- **Files:** `parser/incremental_parser.mbt`
- **Time Taken:** 30 minutes

**Changes made:**
- Updated header to "Wagner-Graham damage tracking algorithm with cache-based optimization"
- Added note about Lezer vs our approach
- Simplified incremental_reparse comments (removed Strategy 2/3 references)
- Clear documentation of what cache invalidation provides

### âœ… Priority 0 Acceptance Criteria - ALL MET

- [x] All documentation reflects actual implementation
- [x] No misleading "Lezer-style" claims
- [x] Clear explanation of what we learned from Lezer
- [x] Honest about recursive descent limitations
- [x] References to actual algorithms used (Wagner-Graham)

**Notes:**
- Task 0.5 (ADR.md) deemed unnecessary - research findings already documented in LEZER_IMPLEMENTATION.md
- All key decisions documented across updated files
- Documentation now provides complete picture for future maintainers

---

## ðŸ§¹ **Priority 1: Remove Dead & Misleading Code** (Week 1, Days 3-5)

**Goal:** Clean up compiler warnings, remove unused/ineffective code

### âœ… Task 1.1: Remove 5 Unused Functions
- [x] Remove `RecoveringParser::next_node_id` (error_recovery.mbt:33)
- [x] Remove `RecoveringParser::peek_info` (error_recovery.mbt:49)
- [x] Remove `RecoveringParser::skip_to_sync` (error_recovery.mbt:63)
- [x] Remove `IncrementalParser::next_node_id` (incremental_parser.mbt:27)
- [x] Remove `peek_info` for basic Parser (parser.mbt:27)
- [x] Run tests to verify no breakage
- [x] Verify compiler warnings disappear
- **Status:** âœ… Complete (2026-01-04)
- **Files:**
  - `parser/error_recovery.mbt` (reduced from 115 lines to 95 lines)
  - `parser/incremental_parser.mbt` (node_id_counter field removed)
  - `parser/parser.mbt` (peek_info function removed)
- **Time Taken:** 15 minutes
- **Lines Removed:** ~20 lines

**What was removed:**
- 3 unused RecoveringParser helper functions (also removed cascading unused `is_sync_point`, `peek`, `advance`)
- Unused `node_id_counter` field from RecoveringParser
- Unused `node_id_counter` field from IncrementalParser
- Unused `peek_info` function from Parser

**Verification:**
```bash
moon check  # âœ… No warnings
moon test   # âœ… All 223 tests passing
```

**Acceptance Criteria:**
- [x] 5+ compiler warnings resolved (actually removed more due to cascading)
- [x] All tests passing (223/223 tests)
- [x] No references to removed functions in codebase

### âœ… Task 1.2: Simplify incremental_reparse
- [x] Remove Strategy 2 (no-op append detection)
- [x] Remove Strategy 3 (ineffective validation)
- [x] Remove 8 helper functions no longer needed
- [x] Update comments to reflect simplified algorithm
- [x] Verify performance (same or better)
- **Status:** âœ… Complete (2026-01-04)
- **Files:** `parser/incremental_parser.mbt` (reduced from 368 lines to 190 lines)
- **Time Taken:** 20 minutes
- **Lines Removed:** 178 lines (from 368 to 190 lines)

**Functions removed:**
- [x] `can_potentially_reuse_with_validation` (23 lines)
- [x] `try_validated_reuse` (58 lines)
- [x] `validate_node_structure` (14 lines)
- [x] `extract_substring` (16 lines)
- [x] `nodes_have_same_structure` (20 lines)
- [x] `kinds_match` (12 lines)
- [x] `collect_reusable_children` (13 lines)
- [x] `can_reuse_node` standalone helper (5 lines)

**Simplified implementation achieved:**
```mbt
fn IncrementalParser::incremental_reparse(...) -> TermNode {
  // Whole-tree reuse
  if self.can_reuse_node(adjusted_tree, damaged_range) &&
    adjusted_tree.start == 0 &&
    adjusted_tree.end == source.length() {
    return adjusted_tree
  }

  // Full reparse with cache benefits
  let (tree, _errors) = parse_with_error_recovery(source)
  tree
}
```

**Verification:**
```bash
moon check  # âœ… No warnings (0 errors, 0 warnings)
moon test   # âœ… All 223 tests passing
```

**Acceptance Criteria:**
- [x] 178 lines of code removed (48% reduction in file size)
- [x] All 223 tests passing (including 35+ incremental parser tests)
- [x] No performance regression (actually faster - less code to execute)
- [x] Code is clearer and easier to understand
- [x] Updated comment from "Lezer-style" to "Wagner-Graham range check"

---

## ðŸ”§ **Priority 2: Fix Parser Duplication** (Week 2-3)

**Goal:** Eliminate ~200 lines of duplicated parsing logic

### âœ… Task 2.1: Unify Parser and PositionedParser
- [x] Remove duplicated Parser struct and all its parsing functions
- [x] Implement node_to_term conversion function
- [x] Make parse() call parse_positioned() and convert result
- [x] Keep PositionedParser as the single source of truth
- [x] Run all parser tests
- [x] Run all incremental parser tests
- **Status:** âœ… Complete (2026-01-04)
- **Files:**
  - `parser/parser.mbt` (334 â†’ 227 lines, -107 lines)
  - `parser/term.mbt` (122 â†’ 182 lines, +60 lines for conversion)
- **Time Taken:** 25 minutes
- **Net Lines Removed:** 47 lines

**Implementation achieved:**
Instead of creating a complex `UnifiedParser` with conditional logic, we took a simpler approach:
1. Removed entire `Parser` struct and all duplicate parsing functions
2. Added `node_to_term()` conversion function in term.mbt (60 lines)
3. Rewrote `parse()` as a 3-line wrapper around `parse_positioned()`
4. Kept `PositionedParser` as the single parser implementation

**Verification:**
```bash
moon check  # âœ… No warnings (0 errors, 0 warnings)
moon test   # âœ… All 223 tests passing
```

**Acceptance Criteria:**
- [x] All parser tests passing (223/223)
- [x] All incremental parser tests passing
- [x] No behavioral changes (same AST output)
- [x] Code duplication eliminated (107 lines of duplicate parser code removed)
- [x] Easier to maintain (single source of truth: PositionedParser)

---

## âš¡ **Priority 3: Performance Optimizations** (Week 2, Optional)

**Goal:** Fix O(nÂ²) bottlenecks, add caching where beneficial

### âœ… Task 3.1: Fix Serialization Performance
- [x] Replace string concatenation with array building
- [x] Implement array building pattern in 5 functions
- [x] Use Array[String].join for final string
- [x] Verify JSON output unchanged
- **Status:** âœ… Complete (2026-01-04)
- **Files:** `serialization.mbt`
- **Time Taken:** 20 minutes
- **Performance Impact:** O(nÂ²) â†’ O(n)

### âœ… Task 3.2: Cache Error Collection
- [x] Add cached_errors field to ParsedEditor
- [x] Update reparse to cache errors on parse
- [x] Implement get_errors using cached value
- [x] Update FFI functions to use cached errors
- [x] Verify error collection still correct
- **Status:** âœ… Complete (2026-01-04)
- **Files:**
  - `editor/parsed_editor.mbt`
  - `crdt.mbt`
- **Time Taken:** 15 minutes
- **Performance Impact:** O(n) every call â†’ O(1) after parse

---

## ðŸ”® **Priority 4: Future Enhancements** (Optional, On-Demand)

**Goal:** Advanced optimizations only if profiling shows need

### ðŸ’¡ Task 4.1: Position-Based Fragment Finding
- [ ] Profile current performance on large files (> 10KB)
- [ ] If needed: Implement find_reusable_top_level_lambdas
- [ ] If needed: Add fragment splicing logic
- [ ] Benchmark improvement
- **Status:** ðŸ”µ Future (Only if profiling shows need)

### ðŸ’¡ Task 4.2: Consider Tree-sitter Migration
- [ ] Evaluate if grammar is expanding significantly
- [ ] Prototype tree-sitter grammar for lambda calculus
- [ ] Compare performance and maintainability
- [ ] Make migration decision
- **Status:** ðŸ”µ Future (Only if requirements change)

---

## ðŸ“‹ **Test Requirements**

All tasks must maintain:

### Unit Tests âœ…
- [x] All 35+ incremental parser tests passing
- [x] All parser tests passing
- [x] All CRDT integration tests passing
- [x] All edge case tests passing

### Benchmarks âœ…
- [x] No performance regressions in core operations
- [x] Improvements measured where claimed
- [x] Memory usage stable or improved

### Verification Commands
```bash
# Run all tests
moon test

# Check for warnings
moon check

# Run benchmarks
moon benchmark parser/performance_benchmark.mbt

# Verify no regressions
git diff HEAD~1 -- parser/BENCHMARKS.md
```

---

## ðŸ“Š **Success Metrics**

### Code Quality âœ…
- [x] Zero compiler warnings
- [x] ~245 lines of code removed total (198 + 47)
- [x] No code duplication in parsers
- [x] Clear, accurate documentation

### Performance âœ…
- [x] Serialization: O(n) instead of O(nÂ²)
- [x] Error collection: O(1) instead of O(n) per call
- [x] Parse performance: < 1ms for typical programs
- [x] Incremental reparse: < 200Âµs for localized edits

### Maintainability âœ…
- [x] Single source of truth for parsing logic
- [x] Clear architecture decisions documented
- [x] Easy to understand for new contributors
- [x] Honest about implementation vs aspirations

---

## ðŸ—“ï¸ **Timeline**

### Week 1: Documentation & Cleanup
- **Days 1-2:** Priority 0 (Documentation updates)
- **Days 3-5:** Priority 1 (Remove dead code, simplify)
- **Deliverable:** Clean, honest codebase with accurate docs

### Week 2: Performance & Quality
- **Days 1-2:** Priority 3 (Performance optimizations)
- **Days 3-5:** Priority 2 (Unify parsers)
- **Deliverable:** Faster, more maintainable parser

### Week 3+: Polish & Future
- **As needed:** Testing, refinement
- **On-demand:** Priority 4 (Advanced features if needed)
- **Deliverable:** Production-ready incremental parser

---

## ðŸ“ **Notes & Decisions**

### Research Findings (2026-01-04)
- Lezer uses position-based fragment reuse with `FragmentCursor.nodeAt(pos)`
- Requires LR parser states for validation via `parser.getGoto(state, nodeType)`
- Recursive descent parsers can't directly implement this without generation
- Tree-sitter shows generated recursive descent CAN do incremental parsing
- Our "3 strategies" were project-specific, not from Lezer/Wagner-Graham
- Cache invalidation provides 70-80% of incremental benefits already

### Key Decisions
- **Don't force GLR patterns** onto recursive descent parser
- **Simplify to what works** for lambda calculus use case
- **Be honest** about implementation vs aspirations in docs
- **Cache is sufficient** for current requirements
- **Future-proof** via clean architecture, not premature optimization

### Open Questions
- [x] ~~Should we keep `RecoveringParser` separate or merge with main parser?~~ â†’ **Deleted** (Phase 0, 2026-02-01). Was never used for actual parsing.
- [x] ~~Is unified parser approach preferred over separate parsers?~~ â†’ Resolved in Priority 2 (single PositionedParser).
- [ ] What performance targets should trigger advanced optimizations?

---

## ðŸ“ˆ **Completion Log**

### 2026-01-04 - Priority 0 Complete âœ…

**What was accomplished:**
- âœ… Created comprehensive TODO.md tracking document
- âœ… Updated STRUCTURAL_VALIDATION.md to reflect Wagner-Graham + cache approach
- âœ… Updated LEZER_IMPLEMENTATION.md with detailed Lezer research findings
- âœ… Updated IMPLEMENTATION_COMPLETE.md with honest status assessment
- âœ… Updated incremental_parser.mbt comments to reflect actual algorithm

### 2026-01-04 - Priority 1 Complete âœ…

**What was accomplished:**
- âœ… Removed 5 unused functions (Task 1.1)
- âœ… Simplified incremental_reparse algorithm (Task 1.2)
- âœ… Removed 8 helper functions from abandoned "Strategy 2/3" approach
- âœ… Eliminated all compiler warnings (0 errors, 0 warnings)

### 2026-01-04 - Priority 2 Complete âœ…

**What was accomplished:**
- âœ… Unified Parser and PositionedParser (Task 2.1)
- âœ… Eliminated all duplicate parsing logic
- âœ… Created single source of truth for parser implementation

### 2026-01-04 - Priority 3 Complete âœ…

**What was accomplished:**
- âœ… Fixed serialization performance (Task 3.1)
- âœ… Implemented error collection caching (Task 3.2)
- âœ… Eliminated all O(nÂ²) performance bottlenecks

### 2026-02-01 - ROADMAP Phase 0 Complete âœ…

**What was accomplished:**
- âœ… Deleted `TokenCache`, `ParseCache`, `RecoveringParser` and all associated code (~581 lines)
- âœ… Removed cache fields and invalidation from `IncrementalParser`
- âœ… Removed duplicate tokenization from `parse_with_error_recovery()`
- âœ… Removed cache-specific tests and benchmarks
- âœ… Updated documentation to remove cache claims
- âœ… Added deprecation notices to historical docs

### 2026-02-01 - Phase 1 (Incremental Lexer) Implemented âœ… (Benchmarks Pending)

**What was accomplished:**
- âœ… Added TokenBuffer with incremental splice updates
- âœ… Integrated incremental lexing into IncrementalParser
- âœ… Added QuickCheck property tests to compare incremental lex vs full tokenize
- âœ… Fixed boundary expansion edge cases (leading whitespace + token boundary edits)

**Pending:**
- â³ Benchmarks on 100+ token inputs to quantify incremental speedup

