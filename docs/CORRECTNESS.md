# Correctness: Incremental Parser

This document defines what correctness means for the incremental parser, how it
is achieved, and what is continuously verified.

## Correctness Goals

### Primary Invariant

For any edit, the incremental parse must produce a tree structurally identical
to a full reparse of the edited source.

In other words:

incremental_parse(source, edit, new_source) == full_parse(new_source)

Structural identity ignores node IDs and other incidental metadata. The
structure, kinds, and token boundaries must match.

### Secondary Invariants

- Tokenization correctness: incremental lexing must match full lexing.
- Error recovery determinism: for the same source, recovery produces the same
  green tree and diagnostic sequence on each run.
- Termination: all inputs (including malformed ones) must terminate without
  panic, producing a tree with ErrorNode/ErrorToken where needed.

## How Correctness Is Achieved

### 1) Conservative Reuse Protocol

Subtree reuse is permitted only when multiple checks succeed:

- Node kind matches the expected kind at the parser checkpoint.
- Node is outside the damaged range (strict inequality at boundaries).
- Leading token kind/text matches the current token stream.
- Trailing context is intended to be validated (Option B: follow-token match).

If any check is uncertain, reuse is skipped and a fresh parse is performed.
Correctness is never traded for reuse.

### 2) Damage Tracking

Edits produce a damaged range using the Wagner-Graham algorithm. Reuse is
disallowed for any subtree overlapping this range, so rebuilt regions are
always parsed from the new source.

### 3) Incremental Lexer Oracle

TokenBuffer updates are verified against full lexing. Token boundaries and
TokenInfo ranges must match exactly. This makes the incremental parser's token
stream a reliable source of truth for both parsing and reuse checks.

### 4) Error Recovery Is Part of Parsing

The parser does not raise on syntax errors. Instead it inserts ErrorNode and
ErrorToken while continuing to parse. This ensures incremental parsing always
has a well-defined output tree, even for incomplete or malformed input.

### 5) Green Tree Identity

Green tree nodes are immutable. Reused subtrees are literally the same nodes,
not copies. This provides a strong correctness foundation for reuse and for
structural comparisons in tests.

### 6) Event-Stream Balance Guard Rails

Green tree construction depends on a balanced parse-event stream:

- Every emitted StartNode must have a matching FinishNode.
- `mark()` / `start_at()` must only claim Tombstone slots exactly once.
- The SourceFile root is implicit and supplied as `root_kind` to
  `build_tree`, not emitted as StartNode/FinishNode events.

To make this robust and maintainable, checks exist at two layers:

- Producer-side (`GreenParser`):
  `open_nodes` tracks StartNode/FinishNode balance during event emission and
  `assert_event_balance()` verifies the stream before calling `build_tree`.
- Consumer-side (`EventBuffer` / `build_tree`):
  `start_at()` validates mark bounds + Tombstone ownership, and `build_tree`
  aborts on unbalanced FinishNode or missing FinishNode at end-of-stream.

This two-layer approach catches regressions both where events are emitted and
where they are consumed.

## Continuous Verification

### Differential Oracle

Every incremental edit is compared against a full reparse. This is the main
correctness oracle and is expected to run in CI.

### Property-Based Fuzzing

Random edits and random inputs are used to validate:

- Incremental vs full parse identity
- Termination under malformed input
- Error recovery stability

### Regression Tests

Any bug found becomes a permanent regression test. The test captures:

- Source before the edit
- Edit specification
- Expected tree after edit
- Event-stream invariant tests:
  `src/green-tree/event_wbtest.mbt` and `src/parser/green_parser_wbtest.mbt`

## Current Edge-Case Findings

These are documented to keep the correctness story honest:

- Trailing-context checks are currently permissive; follow-token comparison is
  the next hardening step (Option B).
- Leading token match for integers currently ignores literal text. This is safe
  under correct damage ranges but weakens the token-level invariant.
- Reuse is conservative around leading whitespace, reducing reuse on
  whitespace-only edits but preserving correctness.
- Adjacent damage is treated as unsafe, which avoids false reuse at
  grammar-sensitive boundaries (application).

## Performance Findings (Profiling)

### Problem Identified

Root-invalidating edits produce many reuse attempts with zero hits. The hot path
was recursive `find_node_at_offset` searches starting from the root on every
call — O(tree) per lookup.

### Optimizations Implemented

Two optimizations reduce search overhead:

1. **Fast path skip:** When the byte offset being queried falls within the
   damaged range (half-open: [start, end)), skip the expensive tree search
   immediately. Tracked via `fast_path_skips` in perf stats.

2. **Stateful cursor:** `ReuseCursor` maintains traversal state using a stack of
   `CursorFrame`s (node + child_index + start_offset). Instead of searching from
   root on every call, the cursor advances incrementally through the tree:
   - Sequential lookups (left-to-right parsing): O(depth) per lookup
   - Backward seeks (shouldn't happen normally): O(tree) reset, then O(depth)

### Measured Results (During Development)

Direct cursor test (4 sequential VarRef lookups in "a b c d e"):
- 4 find_node calls
- 10 total steps (avg 2.5 steps per lookup)
- 1 successful reuse hit

With O(tree) search, each lookup would traverse the entire tree from root.

Note: Production code has instrumentation removed to avoid overhead. These
measurements were taken during profiling.

### Why Timing Benchmarks Show Minimal Change

1. **Small test trees:** Current lambda calculus examples have ~15-30 tokens.
   The O(tree) vs O(depth) difference is more pronounced with larger trees.

2. **Wagner-Graham damage expansion:** For single-expression files, any edit
   causes the root node to overlap with damage, expanding damage to the entire
   tree. This triggers the fast-path skip for all positions.

3. **Tree structure:** Lambda calculus produces deeply nested left-leaning
   spines. The real performance win comes with Phase 5's `let` bindings, which
   create independent top-level subtrees where localized damage is possible.

### When These Optimizations Help

- **Fast path skip:** Any root-invalidating edit (edit at start, structural
  changes) — avoids all tree traversal.
- **Stateful cursor:** Large trees with localized damage and multiple sequential
  reuse lookups — achieves O(depth) instead of O(tree) per lookup.

## Scope of Correctness

Correctness here is strictly about parse tree equivalence between incremental
and full parsing. It does not guarantee:

- Any particular reuse rate or performance improvement
- Semantic equivalence beyond the syntax tree
- Conflict resolution for concurrent edits (CRDT is out of scope)

## Future Work

- Option B: Follow-token comparison for trailing context checks
- Semantics-aware follow-set checks for projectional/live editors
