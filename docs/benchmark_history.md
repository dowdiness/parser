# Benchmark History

Historical snapshots from project benchmark runs (full suite and focused runs).

## 2026-02-25 (ParserDb — term_memo added, AstNode::Eq)

- Command: `moon bench --release`
- Git ref: `main` (uncommitted)
- Environment: local developer machine (WSL2 / Linux 6.6 / wasm-gc)
- Result: `65/65` benchmarks passed (+6 new ParserDb benchmarks)
- Changes since previous entry:
  - `AstKind` gained `Eq` via `derive`; `AstNode` gained structure-only `Eq` (ignores `start`/`end`/`node_id`)
  - `term_memo : Memo[AstNode]` added as fourth pipeline stage in `ParserDb`
  - `tokens_memo` removed from `ParserDb` struct (now owned exclusively by closure captures)
  - `term()` simplified to `self.term_memo.get()` — warm path is now a staleness check only

### Phase 7: ParserDb Signal/Memo Pipeline

| Benchmark | Mean | Notes |
|---|---:|---|
| parserdb: cold — new + term() | 6.23 µs | Full construction + tokenize + parse + AST conversion |
| parserdb: warm — term() no change | 0.03 µs | Memo staleness check only; ~200× faster than cold |
| parserdb: signal no-op — set_source(same) + term() | 0.04 µs | String::Eq short-circuits before any Memo runs |
| parserdb: full recompute — set_source(new) + term() | 13.37 µs | All three Memos recompute |
| parserdb: undo/redo cycle | 13.43 µs | Two full recomputes per iteration |
| parserdb: diagnostics — malformed input | 0.06 µs | Warm path for cached error result |

---

## 2026-02-25 (ParserDb — Salsa-style incremental pipeline added)

- Command: `moon bench --release`
- Git ref: `main` (`0a2139c`)
- Environment: local developer machine (WSL2 / Linux 6.6 / wasm-gc)
- Result: `59/59` benchmarks passed
- Changes since previous entry:
  - `ParserDb` added to `src/incremental/`: `Signal[String]` → `Memo[TokenStage]` → `Memo[CstStage]`
  - `dowdiness/incr` added as git submodule dependency
  - No changes to the parser hot-path; all differences vs previous entry are run-to-run noise

### Phase 3: Cursor Reuse vs Full Reparse (110-token corpus)

| Metric | Mean | Notes |
|---|---:|---|
| phase3: full CST reparse, no cursor - 110 tokens | 21.65 µs | Baseline: pre-tokenized input |
| phase3: cursor reuse, edit at end - 110 tokens | 41.95 µs | 54/55 IntLiterals reusable; cursor overhead dominates |
| phase3: cursor reuse, edit at start - 110 tokens | 36.77 µs | 54/55 IntLiterals reusable; cursor overhead dominates |

### Core Parse Scaling

| Metric | Mean | Notes |
|---|---:|---|
| parse scaling - small (5 tokens) | 1.08 µs | Full parse baseline (small) |
| parse scaling - medium (15 tokens) | 4.74 µs | Full parse baseline (medium) |
| parse scaling - large (30+ tokens) | 7.88 µs | Full parse baseline (large) |

### Incremental Parser

| Metric | Mean | Notes |
|---|---:|---|
| incremental - initial parse | 0.58 µs | Parser creation + first parse |
| incremental - small edit | 2.45 µs | `x` → `x + 1` |
| incremental - multiple edits | 4.10 µs | 2 sequential edits |
| incremental - replacement | 2.67 µs | `λx.x` → `\x.x` |
| incremental vs full - edit at start | 12.79 µs | Boundary edit, medium expression |
| incremental vs full - edit at end | 12.45 µs | Boundary edit, medium expression |
| incremental vs full - edit in middle | 12.69 µs | Boundary edit, medium expression |
| sequential edits - typing simulation | 2.41 µs | Single-char insert |
| sequential edits - backspace simulation | 2.28 µs | Single-char delete |
| incremental state baseline - repeated parsing | 5.04 µs | Edit + undo |
| incremental state baseline - similar expressions | 3.00 µs | Repeated similar parses |
| best case - cosmetic change | 3.20 µs | Localized edit path |
| worst case - full invalidation | 13.87 µs | Full rebuild + incremental overhead |
| memory pressure - large document | 22.18 µs | Larger input incremental edit |

### Damage Tracking & Position Adjustment

| Metric | Mean | Notes |
|---|---:|---|
| damage tracking | 0.94 µs | Wagner-Graham damage expand |
| damage tracking - localized damage | 1.30 µs | Small edit region |
| damage tracking - widespread damage | 5.21 µs | Edit at start of medium expression |
| position adjustment after edit | 2.51 µs | Tree position shift after edit |

### CRDT Integration

| Metric | Mean | Notes |
|---|---:|---|
| tokenization | 0.30 µs | Lexer baseline |
| ast to crdt | 2.39 µs | AST → CRDT conversion |
| crdt to source | 2.54 µs | CRDT → source reconstruction |
| crdt operations - nested structure | 6.81 µs | Nested structure round-trip |
| crdt operations - round trip | 6.70 µs | Parse → CRDT → source → parse |

### Error Recovery & High-level API

| Metric | Mean | Notes |
|---|---:|---|
| error recovery - valid | 0.91 µs | `parse_with_error_recovery`, valid input |
| error recovery - error | 0.96 µs | `parse_with_error_recovery`, invalid input |
| parsed document - parse | 0.73 µs | `ParsedDocument::parse` |
| parsed document - edit | 2.78 µs | `ParsedDocument::edit` |

### Phase 1: Incremental Tokenizer (110-token input)

| Metric | Mean | Notes |
|---|---:|---|
| phase1: full tokenize - 110 tokens | 1.84 µs | Full tokenization baseline |
| phase1: incremental tokenize - edit at start | 3.49 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit in middle | 3.35 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit at end | 3.15 µs | Includes `TokenBuffer::new()` setup |
| phase1: full re-tokenize after edit | 1.88 µs | Comparison baseline |

### Green-Tree Microbenchmarks

| Metric | Mean | Notes |
|---|---:|---|
| green-tree - token constructor | 0.02 µs | `GreenToken::new` hash compute path |
| green-tree - node constructor from 32 children | 0.07 µs | `GreenNode::new` fold/hash/token_count path |
| green-tree - equality identical 32 children | 0.17 µs | Hash check + deep equality walk |
| green-tree - equality mismatch hash fast path | 0.01 µs | Expected early hash mismatch exit |

### Token Interning

| Metric | Mean | Notes |
|---|---:|---|
| interner - intern_token cold miss | 0.10 µs | First call: two-level map miss + `GreenToken::new` |
| interner - intern_token warm hit | 0.08 µs | Subsequent call: two-level map hit, allocation-free |
| build_tree - x + 1 | 0.17 µs | No interning baseline |
| build_tree_interned - x + 1, cold interner | 0.40 µs | First parse (all misses) |
| build_tree_interned - x + 1, warm interner | 0.25 µs | Subsequent parses (all hits); 1.5× vs `build_tree` |
| build_tree - 100 identical ident tokens | 1.09 µs | No interning, 100 `GreenToken::new` calls |
| build_tree_interned - 100 identical tokens, warm | 1.78 µs | 1 miss + 99 hits; 1.6× vs `build_tree` |
| parse_cst_recover - no interner, small | 0.79 µs | `x + 1`, no interning |
| parse_cst_recover - cold interner, small | 1.04 µs | `x + 1`, first parse |
| parse_cst_recover - warm interner, small | 0.87 µs | `x + 1`, subsequent; 1.10× overhead |
| parse_cst_recover - no interner, large | 6.39 µs | `λf.λx.if…`, no interning |
| parse_cst_recover - warm interner, large | 7.05 µs | `λf.λx.if…`, subsequent; 1.10× overhead |

### Notable Changes vs 2026-02-24 (generic incremental reuse)

`ParserDb` adds a new `src/incremental/` package on top of the existing pipeline;
it does not modify any hot-path code. All differences vs the previous snapshot are
within run-to-run noise on the same machine:

| Metric | prev | today | Change |
|---|---:|---:|---|
| parse scaling - small (5 tokens) | 1.07 µs | 1.08 µs | +1% (noise) |
| parse scaling - large (30+ tokens) | 7.75 µs | 7.88 µs | +2% (noise) |
| worst case - full invalidation | 12.44 µs | 13.87 µs | +11% (noise/scheduling) |
| memory pressure - large document | 20.98 µs | 22.18 µs | +6% (noise) |
| phase3: full CST reparse | 21.19 µs | 21.65 µs | +2% (noise) |
| phase3: cursor reuse, edit at end | 42.32 µs | 41.95 µs | -1% (noise) |

## 2026-02-24 (generic incremental reuse — Phase 3 cursor wired)

- Command: `moon bench --package dowdiness/parser/benchmarks --release`
- Git ref: `main` (`2e0242b`)
- Environment: local developer machine (WSL2 / Linux 6.6 / wasm-gc)
- Result: `59/59` benchmarks passed
- Changes since previous entry:
  - `ReuseCursor[T, K]` generalized to `src/core/`; old lambda-specific cursor removed
  - Lambda grammar migrated: `parse_atom` uses `ctx.node()`, binary/app rules use `ctx.wrap_at()`
  - `run_parse_incremental` wires `ReuseCursor` into `ParserContext` via `set_reuse_cursor`
  - Three new Phase 3 cursor benchmarks added (see below)
  - 8 new tests (source-shrink/grow, multi-region, boundary merge, diagnostic replay)

### Phase 3: Cursor Reuse vs Full Reparse (110-token corpus)

| Metric | Mean | Notes |
|---|---:|---|
| phase3: full green reparse, no cursor - 110 tokens | 21.19 µs | Baseline: pre-tokenized input, cursor setup matched |
| phase3: cursor reuse, edit at end - 110 tokens | 42.32 µs | 54/55 IntLiterals reusable; cursor overhead dominates |
| phase3: cursor reuse, edit at start - 110 tokens | 38.48 µs | 54/55 IntLiterals reusable; cursor overhead dominates |

**Key finding:** For the 110-token flat `BinaryExpr` corpus, cursor overhead (~2×) exceeds
reuse savings because `collect_old_tokens` (O(n) tree walk in `ReuseCursor::new`) runs on
every iteration, and the reused nodes (`IntLiteral`) are each just one token. Cursor reuse
shows net benefit when reused subtrees contain many tokens (e.g. large lambda bodies in a
multi-definition file). These benchmarks establish the baseline for future cursor optimization.

### Core Parse Scaling

| Metric | Mean | Notes |
|---|---:|---|
| parse scaling - small (5 tokens) | 1.07 µs | Full parse baseline (small) |
| parse scaling - medium (15 tokens) | 4.70 µs | Full parse baseline (medium) |
| parse scaling - large (30+ tokens) | 7.75 µs | Full parse baseline (large) |

### Incremental Parser

| Metric | Mean | Notes |
|---|---:|---|
| incremental - initial parse | 0.56 µs | Parser creation + first parse |
| incremental - small edit | 2.18 µs | `x` → `x + 1` |
| incremental - multiple edits | 3.80 µs | 2 sequential edits |
| incremental - replacement | 2.53 µs | `λx.x` → `\x.x` |
| incremental vs full - edit at start | 12.61 µs | Boundary edit, medium expression |
| incremental vs full - edit at end | 12.52 µs | Boundary edit, medium expression |
| incremental vs full - edit in middle | 12.57 µs | Boundary edit, medium expression |
| sequential edits - typing simulation | 2.20 µs | Single-char insert |
| sequential edits - backspace simulation | 2.21 µs | Single-char delete |
| incremental state baseline - repeated parsing | 5.06 µs | Edit + undo |
| best case - cosmetic change | 3.01 µs | Localized edit path |
| worst case - full invalidation | 12.44 µs | Full rebuild + incremental overhead |
| memory pressure - large document | 20.98 µs | Larger input incremental edit |

### Damage Tracking & Position Adjustment

| Metric | Mean | Notes |
|---|---:|---|
| damage tracking | 0.92 µs | Wagner-Graham damage expand |
| damage tracking - localized damage | 1.28 µs | Small edit region |
| damage tracking - widespread damage | 5.17 µs | Edit at start of medium expression |
| position adjustment after edit | 2.48 µs | Tree position shift after edit |

### CRDT Integration

| Metric | Mean | Notes |
|---|---:|---|
| tokenization | 0.31 µs | Lexer baseline |
| ast to crdt | 2.39 µs | AST → CRDT conversion |
| crdt to source | 2.59 µs | CRDT → source reconstruction |
| crdt operations - nested structure | 6.49 µs | Nested structure round-trip |
| crdt operations - round trip | 6.50 µs | Parse → CRDT → source → parse |

### Error Recovery & High-level API

| Metric | Mean | Notes |
|---|---:|---|
| error recovery - valid | 0.91 µs | `parse_with_error_recovery`, valid input |
| error recovery - error | 1.02 µs | `parse_with_error_recovery`, invalid input |
| parsed document - parse | 0.72 µs | `ParsedDocument::parse` |
| parsed document - edit | 2.75 µs | `ParsedDocument::edit` |

### Phase 1: Incremental Tokenizer (110-token input)

| Metric | Mean | Notes |
|---|---:|---|
| phase1: full tokenize - 110 tokens | 1.78 µs | Full tokenization baseline |
| phase1: incremental tokenize - edit at start | 3.50 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit in middle | 3.34 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit at end | 3.06 µs | Includes `TokenBuffer::new()` setup |
| phase1: full re-tokenize after edit | 1.83 µs | Comparison baseline |

### Green-Tree Microbenchmarks

| Metric | Mean | Notes |
|---|---:|---|
| green-tree - token constructor | 0.02 µs | `GreenToken::new` hash compute path |
| green-tree - node constructor from 32 children | 0.08 µs | `GreenNode::new` fold/hash/token_count path |
| green-tree - equality identical 32 children | 0.17 µs | Hash check + deep equality walk |
| green-tree - equality mismatch hash fast path | 0.01 µs | Expected early hash mismatch exit |

### Token Interning

| Metric | Mean | Notes |
|---|---:|---|
| interner - intern_token cold miss | 0.10 µs | First call: two-level map miss + `GreenToken::new` |
| interner - intern_token warm hit | 0.08 µs | Subsequent call: two-level map hit, allocation-free |
| build_tree - x + 1 | 0.17 µs | No interning baseline |
| build_tree_interned - x + 1, cold interner | 0.40 µs | First parse (all misses) |
| build_tree_interned - x + 1, warm interner | 0.24 µs | Subsequent parses (all hits); 1.4× vs `build_tree` |
| build_tree - 100 identical ident tokens | 1.13 µs | No interning, 100 `GreenToken::new` calls |
| build_tree_interned - 100 identical tokens, warm | 1.81 µs | 1 miss + 99 hits; 1.6× vs `build_tree` |
| parse_green_recover - no interner, small | 0.80 µs | `x + 1`, no interning |
| parse_green_recover - cold interner, small | 1.06 µs | `x + 1`, first parse |
| parse_green_recover - warm interner, small | 0.90 µs | `x + 1`, subsequent; 1.13× overhead |
| parse_green_recover - no interner, large | 6.49 µs | `λf.λx.if…`, no interning |
| parse_green_recover - warm interner, large | 7.05 µs | `λf.λx.if…`, subsequent; 1.09× overhead |

### Notable Changes vs 2026-02-24 (generic ParserContext)

Incremental parser numbers are slightly higher than the previous 2026-02-24 snapshot
because `ctx.node()` performs a cursor check on every grammar combinator call (even when
`reuse_cursor` is `None`, the `match` adds a branch). This is the intentional "zero overhead
without cursor" design — the branch is predicted-not-taken in practice.

| Metric | prev | today | Change |
|---|---:|---:|---|
| parse scaling - small (5 tokens) | 1.01 µs | 1.07 µs | +6% (node() match branch) |
| parse scaling - medium (15 tokens) | 4.66 µs | 4.70 µs | +1% (noise) |
| parse scaling - large (30+ tokens) | 7.67 µs | 7.75 µs | +1% (noise) |
| incremental vs full - edit at start | 11.59 µs | 12.61 µs | +9% (node() + wrap_at() overhead) |
| memory pressure - large document | 18.73 µs | 20.98 µs | +12% (node() on every atom) |

## 2026-02-24 (generic ParserContext — closure-based token storage)

- Command: `moon bench --release`
- Git ref: `feature/generic-parser-core` (`2f19c82`)
- Environment: local developer machine (WSL2 / Linux 6.6 / wasm-gc)
- Result: `56/56` benchmarks passed
- Changes since previous entry:
  - `ParserContext[T, K]` storage changed from `tokens : Array[TokenInfo[T]]`
    to closure-based indexed accessors (`token_count`, `get_token`, `get_start`,
    `get_end`); `new_indexed` constructor avoids allocating a wrapper array
  - `run_parse` now passes `@token.TokenInfo` directly via `new_indexed`,
    eliminating the O(n) `Array[@core.TokenInfo]` allocation on every parse call
  - `Diagnostic[T]` gains `got_token : T`; `token_at_offset` (second full
    tokenize pass on the error path) deleted
  - `LanguageSpec` gains `print_token : (T) -> String`
  - `emit_error_placeholder()` added to `ParserContext` (no-arg convenience
    around `emit_zero_width(spec.error_kind)`)

### Core Parse Scaling

| Metric | Mean | Notes |
|---|---:|---|
| parse scaling - small (5 tokens) | 1.01 µs | Full parse baseline (small) |
| parse scaling - medium (15 tokens) | 4.66 µs | Full parse baseline (medium) |
| parse scaling - large (30+ tokens) | 7.67 µs | Full parse baseline (large) |

### Incremental Parser

| Metric | Mean | Notes |
|---|---:|---|
| incremental - initial parse | 0.56 µs | Parser creation + first parse |
| incremental - small edit | 1.98 µs | `x` → `x + 1` |
| incremental - multiple edits | 3.43 µs | 2 sequential edits |
| incremental - replacement | 2.35 µs | `λx.x` → `\x.x` |
| incremental vs full - edit at start | 11.59 µs | Boundary edit, medium expression |
| incremental vs full - edit at end | 11.56 µs | Boundary edit, medium expression |
| incremental vs full - edit in middle | 11.65 µs | Boundary edit, medium expression |
| sequential edits - typing simulation | 2.00 µs | Single-char insert |
| sequential edits - backspace simulation | 2.14 µs | Single-char delete |
| incremental state baseline - repeated parsing | 4.52 µs | Edit + undo |
| incremental state baseline - similar expressions | 2.81 µs | Repeated similar parses |
| best case - cosmetic change | 2.79 µs | Localized edit path |
| worst case - full invalidation | 11.46 µs | Full rebuild + incremental overhead |
| memory pressure - large document | 18.73 µs | Larger input incremental edit |

### Damage Tracking & Position Adjustment

| Metric | Mean | Notes |
|---|---:|---|
| damage tracking | 0.86 µs | Wagner-Graham damage expand |
| damage tracking - localized damage | 1.22 µs | Small edit region |
| damage tracking - widespread damage | 4.96 µs | Edit at start of medium expression |
| position adjustment after edit | 2.38 µs | Tree position shift after edit |

### CRDT Integration

| Metric | Mean | Notes |
|---|---:|---|
| tokenization | 0.29 µs | Lexer baseline |
| ast to crdt | 2.26 µs | AST → CRDT conversion |
| crdt to source | 2.45 µs | CRDT → source reconstruction |
| crdt operations - nested structure | 6.29 µs | Nested structure round-trip |
| crdt operations - round trip | 6.08 µs | Parse → CRDT → source → parse |

### Error Recovery & High-level API

| Metric | Mean | Notes |
|---|---:|---|
| error recovery - valid | 0.84 µs | `parse_with_error_recovery`, valid input |
| error recovery - error | 0.89 µs | `parse_with_error_recovery`, invalid input |
| parsed document - parse | 0.73 µs | `ParsedDocument::parse` |
| parsed document - edit | 2.47 µs | `ParsedDocument::edit` |

### Phase 1: Incremental Tokenizer (110-token input)

| Metric | Mean | Notes |
|---|---:|---|
| phase1: full tokenize - 110 tokens | 1.79 µs | Full tokenization baseline |
| phase1: incremental tokenize - edit at start | 3.50 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit in middle | 3.33 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit at end | 3.17 µs | Includes `TokenBuffer::new()` setup |
| phase1: full re-tokenize after edit | 1.80 µs | Comparison baseline |

### Green-Tree Microbenchmarks

| Metric | Mean | Notes |
|---|---:|---|
| green-tree - token constructor | 0.02 µs | `GreenToken::new` hash compute path |
| green-tree - node constructor from 32 children | 0.08 µs | `GreenNode::new` fold/hash/token_count path |
| green-tree - equality identical 32 children | 0.18 µs | Hash check + deep equality walk |
| green-tree - equality mismatch hash fast path | 0.01 µs | Expected early hash mismatch exit |

### Token Interning

| Metric | Mean | Notes |
|---|---:|---|
| interner - intern_token cold miss | 0.10 µs | First call: two-level map miss + `GreenToken::new` |
| interner - intern_token warm hit | 0.08 µs | Subsequent call: two-level map hit, allocation-free |
| build_tree - x + 1 | 0.18 µs | No interning baseline (11 token events incl. whitespace) |
| build_tree_interned - x + 1, cold interner | 0.42 µs | First parse (all misses) |
| build_tree_interned - x + 1, warm interner | 0.24 µs | Subsequent parses (all hits); 1.3× vs `build_tree` |
| build_tree - 100 identical ident tokens | 1.16 µs | No interning, 100 `GreenToken::new` calls |
| build_tree_interned - 100 identical tokens, warm | 1.87 µs | 1 miss + 99 hits; 1.6× vs `build_tree` |
| parse_green_recover - no interner, small | 0.73 µs | `x + 1`, no interning |
| parse_green_recover - cold interner, small | 0.97 µs | `x + 1`, first parse |
| parse_green_recover - warm interner, small | 0.81 µs | `x + 1`, subsequent; 1.11× overhead |
| parse_green_recover - no interner, large | 6.06 µs | `λf.λx.if…`, no interning |
| parse_green_recover - warm interner, large | 7.02 µs | `λf.λx.if…`, subsequent; 1.16× overhead |

### Notable Changes vs 2026-02-23 (trivia-inclusive lexer)

The closure-based `ParserContext` replaces direct array indexing with indirect
function calls (`(self.get_token)(pos)` etc.), adding a measurable dispatch
overhead on every token access. The eliminated O(n) wrapper-array allocation
does not compensate at these expression sizes, where the token count is low and
allocation is cheap. The trade-off is intentional: `new_indexed` enables
zero-copy construction for callers with a different token layout (e.g. LSP
incremental editing), and the absolute numbers remain well within the 16 ms
real-time budget.

| Metric | prev | today | Change |
|---|---:|---:|---|
| parse scaling - small (5 tokens) | 0.92 µs | 1.01 µs | +10% (closure dispatch) |
| parse scaling - medium (15 tokens) | 3.90 µs | 4.66 µs | +20% (closure dispatch) |
| parse scaling - large (30+ tokens) | 6.50 µs | 7.67 µs | +18% (closure dispatch) |
| parse_green_recover - no interner, small | 0.65 µs | 0.73 µs | +12% |
| parse_green_recover - no interner, large | 5.04 µs | 6.06 µs | +20% |
| incremental vs full - edit at start | 10.64 µs | 11.59 µs | +9% |
| memory pressure - large document | 17.32 µs | 18.73 µs | +8% |
| worst case - full invalidation | 10.62 µs | 11.46 µs | +8% |

## 2026-02-23 (trivia-inclusive lexer)

- Command: `moon bench --package dowdiness/parser/benchmarks --release`
- Git ref: `feature/trivia-inclusive-lexer` (`114d91e`)
- Environment: local developer machine (WSL2 / Linux 6.6 / wasm-gc)
- Result: `56/56` benchmarks passed
- Changes since previous entry:
  - Lexer now emits `Whitespace` tokens for every whitespace span (previously
    whitespace was silently skipped during tokenization)
  - `GreenParser` absorbs trivia inline via `flush_trivia()` called before each
    token is consumed; the separate pre-scan for leading whitespace is gone
  - `last_end` field removed from `GreenParser` (trivia cursor tracks position
    implicitly via the token stream)
  - `emit_whitespace_before` and `trailing_context_matches` parameters removed
    (dead code eliminated)
  - Net result: one source scan instead of two for full parses; incremental paths
    unaffected

### Core Parse Scaling

| Metric | Mean | Notes |
|---|---:|---|
| parse scaling - small (5 tokens) | 0.92 µs | Full parse baseline (small) |
| parse scaling - medium (15 tokens) | 3.90 µs | Full parse baseline (medium) |
| parse scaling - large (30+ tokens) | 6.50 µs | Full parse baseline (large) |

### Incremental Parser

| Metric | Mean | Notes |
|---|---:|---|
| incremental - initial parse | 0.54 µs | Parser creation + first parse |
| incremental - small edit | 2.02 µs | `x` → `x + 1` |
| incremental - multiple edits | 3.35 µs | 2 sequential edits |
| incremental - replacement | 2.28 µs | `λx.x` → `\x.x` |
| incremental vs full - edit at start | 10.64 µs | Boundary edit, medium expression |
| incremental vs full - edit at end | 10.38 µs | Boundary edit, medium expression |
| incremental vs full - edit in middle | 10.57 µs | Boundary edit, medium expression |
| sequential edits - typing simulation | 1.97 µs | Single-char insert |
| sequential edits - backspace simulation | 1.98 µs | Single-char delete |
| incremental state baseline - repeated parsing | 4.49 µs | Edit + undo |
| best case - cosmetic change | 2.76 µs | Localized edit path |
| worst case - full invalidation | 10.62 µs | Full rebuild + incremental overhead |
| memory pressure - large document | 17.32 µs | Larger input incremental edit |

### Damage Tracking & Position Adjustment

| Metric | Mean | Notes |
|---|---:|---|
| damage tracking | 0.82 µs | Wagner-Graham damage expand |
| damage tracking - localized damage | 1.09 µs | Small edit region |
| damage tracking - widespread damage | 4.39 µs | Edit at start of medium expression |
| position adjustment after edit | 2.23 µs | Tree position shift after edit |

### CRDT Integration

| Metric | Mean | Notes |
|---|---:|---|
| tokenization | 0.30 µs | Lexer baseline |
| ast to crdt | 2.15 µs | AST → CRDT conversion |
| crdt to source | 2.34 µs | CRDT → source reconstruction |
| crdt operations - nested structure | 5.79 µs | Nested structure round-trip |
| crdt operations - round trip | 5.71 µs | Parse → CRDT → source → parse |

### Error Recovery & High-level API

| Metric | Mean | Notes |
|---|---:|---|
| error recovery - valid | 0.78 µs | `parse_with_error_recovery`, valid input |
| error recovery - error | 0.84 µs | `parse_with_error_recovery`, invalid input |
| parsed document - parse | 0.70 µs | `ParsedDocument::parse` |
| parsed document - edit | 2.55 µs | `ParsedDocument::edit` |

### Phase 1: Incremental Tokenizer (110-token input)

| Metric | Mean | Notes |
|---|---:|---|
| phase1: full tokenize - 110 tokens | 1.90 µs | Full tokenization baseline (now includes whitespace tokens) |
| phase1: incremental tokenize - edit at start | 3.56 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit in middle | 3.33 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit at end | 3.13 µs | Includes `TokenBuffer::new()` setup |
| phase1: full re-tokenize after edit | 1.82 µs | Comparison baseline |

### Green-Tree Microbenchmarks

| Metric | Mean | Notes |
|---|---:|---|
| green-tree - token constructor | 0.02 µs | `GreenToken::new` hash compute path |
| green-tree - node constructor from 32 children | 0.08 µs | `GreenNode::new` fold/hash/token_count path |
| green-tree - equality identical 32 children | 0.17 µs | Hash check + deep equality walk |
| green-tree - equality mismatch hash fast path | 0.01 µs | Expected early hash mismatch exit |

### Token Interning

| Metric | Mean | Notes |
|---|---:|---|
| interner - intern_token cold miss | 0.10 µs | First call: two-level map miss + `GreenToken::new` |
| interner - intern_token warm hit | 0.08 µs | Subsequent call: two-level map hit, allocation-free |
| build_tree - x + 1 | 0.17 µs | No interning baseline (now 11 token events incl. whitespace) |
| build_tree_interned - x + 1, cold interner | 0.41 µs | First parse (all misses) |
| build_tree_interned - x + 1, warm interner | 0.24 µs | Subsequent parses (all hits); 1.4× vs `build_tree` |
| build_tree - 100 identical ident tokens | 1.14 µs | No interning, 100 `GreenToken::new` calls |
| build_tree_interned - 100 identical tokens, warm | 1.84 µs | 1 miss + 99 hits; 1.6× vs `build_tree` |
| parse_green_recover - no interner, small | 0.65 µs | `x + 1`, no interning |
| parse_green_recover - cold interner, small | 0.91 µs | `x + 1`, first parse |
| parse_green_recover - warm interner, small | 0.73 µs | `x + 1`, subsequent; 1.13× overhead |
| parse_green_recover - no interner, large | 5.04 µs | `λf.λx.if…`, no interning |
| parse_green_recover - warm interner, large | 5.89 µs | `λf.λx.if…`, subsequent; 1.17× overhead |

### Notable Changes vs 2026-02-23 (token_count caching)

The main observable impact of the trivia-inclusive refactor is in the tokenizer
benchmarks, where the 110-token input now also contains whitespace tokens. Full
parse and incremental parser numbers are within run-to-run noise of the previous
snapshot:

| Metric | prev | today | Change |
|---|---:|---:|---|
| parse scaling - small (5 tokens) | 0.87 µs | 0.92 µs | +6% (noise/whitespace tokens in tree) |
| parse scaling - large (30+ tokens) | 6.36 µs | 6.50 µs | +2% (noise) |
| phase1: full tokenize - 110 tokens | 1.16 µs | 1.90 µs | +64% (whitespace tokens emitted; more tokens produced) |
| phase1: incremental tokenize - edit at start | 2.11 µs | 3.56 µs | +69% (larger token arrays with whitespace) |
| best case - cosmetic change | 2.57 µs | 2.76 µs | +7% (noise) |
| incremental vs full - edit at start | 10.13 µs | 10.64 µs | +5% (noise) |
| memory pressure - large document | 16.75 µs | 17.32 µs | +3% (noise) |

The tokenizer throughput increase is expected: the 110-token arithmetic source
`"1 + 2 + ... + 55"` now produces ~218 tokens (55 integer + 54 plus +
108 whitespace + 1 EOF) instead of 110. The 108 whitespace spans come from one
space before and one space after each of the 54 `+` operators. The incremental
tokenizer benchmarks reflect this larger token array size. Full-parse and
incremental-edit paths remain within noise because `flush_trivia` is
O(whitespace tokens consumed) and the parser walks the same source text as before.

## 2026-02-23 (token_count caching)

- Command: `moon bench --package dowdiness/parser/benchmarks --release`
- Git ref: `main` (`cda3ed9`)
- Environment: local developer machine (WSL2 / Linux 6.6 / wasm-gc)
- Result: `56/56` benchmarks passed
- Changes since previous entry:
  - Added `token_count : Int` field to `GreenNode`, computed in `GreenNode::new`'s
    existing children loop (same pass as `text_len` and `hash`)
  - Optional `trivia_kind?` parameter on `GreenNode::new`, `build_tree`,
    `build_tree_interned`; parser passes `Some(WhitespaceToken)` so every
    incremental-parsed tree carries the non-whitespace count
  - Removed `count_tokens_in_node` (reuse_cursor) and `count_tokens_in_green`
    (green_parser) — both O(subtree) recursive traversals; replaced with
    `node.token_count` (O(1)) at all call sites

### Core Parse Scaling

| Metric | Mean | Notes |
|---|---:|---|
| parse scaling - small (5 tokens) | 0.87 µs | Full parse baseline (small) |
| parse scaling - medium (15 tokens) | 3.76 µs | Full parse baseline (medium) |
| parse scaling - large (30+ tokens) | 6.36 µs | Full parse baseline (large) |

### Incremental Parser

| Metric | Mean | Notes |
|---|---:|---|
| incremental - initial parse | 0.52 µs | Parser creation + first parse |
| incremental - small edit | 1.96 µs | `x` → `x + 1` |
| incremental - multiple edits | 3.26 µs | 2 sequential edits |
| incremental - replacement | 2.22 µs | `λx.x` → `\x.x` |
| incremental vs full - edit at start | 10.13 µs | Boundary edit, medium expression |
| incremental vs full - edit at end | 10.03 µs | Boundary edit, medium expression |
| incremental vs full - edit in middle | 10.49 µs | Boundary edit, medium expression |
| sequential edits - typing simulation | 1.97 µs | Single-char insert |
| sequential edits - backspace simulation | 1.97 µs | Single-char delete |
| incremental state baseline - repeated parsing | 4.43 µs | Edit + undo |
| best case - cosmetic change | 2.57 µs | Localized edit path |
| worst case - full invalidation | 10.11 µs | Full rebuild + incremental overhead |
| memory pressure - large document | 16.75 µs | Larger input incremental edit |

### Damage Tracking & Position Adjustment

| Metric | Mean | Notes |
|---|---:|---|
| damage tracking | 0.80 µs | Wagner-Graham damage expand |
| damage tracking - localized damage | 1.09 µs | Small edit region |
| damage tracking - widespread damage | 4.25 µs | Edit at start of medium expression |
| position adjustment after edit | 2.12 µs | Tree position shift after edit |

### CRDT Integration

| Metric | Mean | Notes |
|---|---:|---|
| tokenization | 0.30 µs | Lexer baseline |
| ast to crdt | 2.06 µs | AST → CRDT conversion |
| crdt to source | 2.24 µs | CRDT → source reconstruction |
| crdt operations - nested structure | 5.55 µs | Nested structure round-trip |
| crdt operations - round trip | 5.44 µs | Parse → CRDT → source → parse |

### Error Recovery & High-level API

| Metric | Mean | Notes |
|---|---:|---|
| error recovery - valid | 0.78 µs | `parse_with_error_recovery`, valid input |
| error recovery - error | 0.85 µs | `parse_with_error_recovery`, invalid input |
| parsed document - parse | 0.67 µs | `ParsedDocument::parse` |
| parsed document - edit | 2.51 µs | `ParsedDocument::edit` |

### Phase 1: Incremental Tokenizer (110-token input)

| Metric | Mean | Notes |
|---|---:|---|
| phase1: full tokenize - 110 tokens | 1.16 µs | Full tokenization baseline |
| phase1: incremental tokenize - edit at start | 2.11 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit in middle | 2.02 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit at end | 1.97 µs | Includes `TokenBuffer::new()` setup |
| phase1: full re-tokenize after edit | 1.23 µs | Comparison baseline |

### Green-Tree Microbenchmarks

| Metric | Mean | Notes |
|---|---:|---|
| green-tree - token constructor | 0.02 µs | `GreenToken::new` hash compute path |
| green-tree - node constructor from 32 children | 0.08 µs | `GreenNode::new` fold/hash/token_count path |
| green-tree - equality identical 32 children | 0.18 µs | Hash check + deep equality walk |
| green-tree - equality mismatch hash fast path | 0.01 µs | Expected early hash mismatch exit |

### Token Interning

| Metric | Mean | Notes |
|---|---:|---|
| interner - intern_token cold miss | 0.10 µs | First call: two-level map miss + `GreenToken::new` |
| interner - intern_token warm hit | 0.08 µs | Subsequent call: two-level map hit, allocation-free |
| build_tree - x + 1 | 0.18 µs | No interning baseline (7 token events) |
| build_tree_interned - x + 1, cold interner | 0.41 µs | First parse (all misses) |
| build_tree_interned - x + 1, warm interner | 0.26 µs | Subsequent parses (all hits); 1.4× vs `build_tree` |
| build_tree - 100 identical ident tokens | 1.15 µs | No interning, 100 `GreenToken::new` calls |
| build_tree_interned - 100 identical tokens, warm | 1.83 µs | 1 miss + 99 hits; 1.6× vs `build_tree` |
| parse_green_recover - no interner, small | 0.64 µs | `x + 1`, no interning |
| parse_green_recover - cold interner, small | 0.89 µs | `x + 1`, first parse |
| parse_green_recover - warm interner, small | 0.72 µs | `x + 1`, subsequent; 1.13× overhead |
| parse_green_recover - no interner, large | 4.88 µs | `λf.λx.if…`, no interning |
| parse_green_recover - warm interner, large | 5.58 µs | `λf.λx.if…`, subsequent; 1.14× overhead |

### Notable Changes vs 2026-02-23 (interner key fix)

`token_count` computation adds one `match` per child in `GreenNode::new`. This
is measurable only in the construction microbenchmark; all reuse and incremental
paths are within run-to-run noise:

| Metric | prev | today | Change |
|---|---:|---:|---|
| green-tree - node constructor (32 children) | 0.06 µs | 0.08 µs | +33% (token_count loop) |
| build_tree - x + 1 | 0.17 µs | 0.18 µs | +6% |
| best case - cosmetic change | 2.53 µs | 2.57 µs | +2% (noise) |
| incremental vs full - edit at start | 10.15 µs | 10.13 µs | -0% (noise) |
| memory pressure - large document | 16.53 µs | 16.75 µs | +1% (noise) |

The asymptotic benefit (O(1) instead of O(subtree) on every successful reuse)
does not surface at these expression sizes. It becomes material when reusing
large subtrees (hundreds of tokens) in a language server scenario.

## 2026-02-23

- Command: `moon bench --package dowdiness/parser/benchmarks --release`
- Git ref: `main` (`23b71da`)
- Environment: local developer machine (WSL2 / Linux 6.6 / wasm-gc)
- Result: `56/56` benchmarks passed
- Changes since previous entry:
  - Added token interning (`Interner`, `build_tree_interned`) to `green-tree`
  - `IncrementalParser` now owns a session-scoped `Interner`
  - Fixed interner key construction: two-level `HashMap[RawKind, HashMap[String, GreenToken]]`
    replaces the old string-concat key; hot hit path is allocation-free
  - Added 12 new interning benchmarks (interner micro, `build_tree` comparison, `parse_green_recover` comparison)

### Core Parse Scaling

| Metric | Mean | Notes |
|---|---:|---|
| parse scaling - small (5 tokens) | 0.86 µs | Full parse baseline (small) |
| parse scaling - medium (15 tokens) | 3.71 µs | Full parse baseline (medium) |
| parse scaling - large (30+ tokens) | 6.25 µs | Full parse baseline (large) |

### Incremental Parser

| Metric | Mean | Notes |
|---|---:|---|
| incremental - initial parse | 0.53 µs | Parser creation + first parse |
| incremental - small edit | 1.94 µs | `x` → `x + 1` |
| incremental - multiple edits | 3.23 µs | 2 sequential edits |
| incremental - replacement | 2.24 µs | `λx.x` → `\x.x` |
| incremental vs full - edit at start | 10.15 µs | Boundary edit, medium expression |
| incremental vs full - edit at end | 9.93 µs | Boundary edit, medium expression |
| incremental vs full - edit in middle | 10.28 µs | Boundary edit, medium expression |
| sequential edits - typing simulation | 1.90 µs | Single-char insert |
| sequential edits - backspace simulation | 1.95 µs | Single-char delete |
| incremental state baseline - repeated parsing | 4.44 µs | Edit + undo |
| best case - cosmetic change | 2.53 µs | Localized edit path |
| worst case - full invalidation | 10.17 µs | Full rebuild + incremental overhead |
| memory pressure - large document | 16.53 µs | Larger input incremental edit |

### Damage Tracking & Position Adjustment

| Metric | Mean | Notes |
|---|---:|---|
| damage tracking | 0.79 µs | Wagner-Graham damage expand |
| damage tracking - localized damage | 1.08 µs | Small edit region |
| damage tracking - widespread damage | 4.20 µs | Edit at start of medium expression |
| position adjustment after edit | 2.14 µs | Tree position shift after edit |

### CRDT Integration

| Metric | Mean | Notes |
|---|---:|---|
| tokenization | 0.29 µs | Lexer baseline |
| ast to crdt | 2.10 µs | AST → CRDT conversion |
| crdt to source | 2.26 µs | CRDT → source reconstruction |
| crdt operations - nested structure | 5.61 µs | Nested structure round-trip |
| crdt operations - round trip | 5.39 µs | Parse → CRDT → source → parse |

### Error Recovery & High-level API

| Metric | Mean | Notes |
|---|---:|---|
| error recovery - valid | 0.76 µs | `parse_with_error_recovery`, valid input |
| error recovery - error | 0.80 µs | `parse_with_error_recovery`, invalid input |
| parsed document - parse | 0.66 µs | `ParsedDocument::parse` |
| parsed document - edit | 2.43 µs | `ParsedDocument::edit` |

### Phase 1: Incremental Tokenizer (110-token input)

| Metric | Mean | Notes |
|---|---:|---|
| phase1: full tokenize - 110 tokens | 1.21 µs | Full tokenization baseline |
| phase1: incremental tokenize - edit at start | 2.17 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit in middle | 1.97 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit at end | 1.89 µs | Includes `TokenBuffer::new()` setup |
| phase1: full re-tokenize after edit | 1.17 µs | Comparison baseline |

### Green-Tree Microbenchmarks

| Metric | Mean | Notes |
|---|---:|---|
| green-tree - token constructor | 0.02 µs | `GreenToken::new` hash compute path |
| green-tree - node constructor from 32 children | 0.06 µs | `GreenNode::new` fold/hash path |
| green-tree - equality identical 32 children | 0.17 µs | Hash check + deep equality walk |
| green-tree - equality mismatch hash fast path | 0.01 µs | Expected early hash mismatch exit |

### Token Interning (new — baseline for future node-interning evaluation)

| Metric | Mean | Notes |
|---|---:|---|
| interner - intern_token cold miss | 0.10 µs | First call: two-level map miss + `GreenToken::new` |
| interner - intern_token warm hit | 0.07 µs | Subsequent call: two-level map hit, allocation-free |
| build_tree - x + 1 | 0.17 µs | No interning baseline (7 token events) |
| build_tree_interned - x + 1, cold interner | 0.41 µs | First parse (all misses) |
| build_tree_interned - x + 1, warm interner | 0.24 µs | Subsequent parses (all hits); 1.4× vs `build_tree` |
| build_tree - 100 identical ident tokens | 1.09 µs | No interning, 100 `GreenToken::new` calls |
| build_tree_interned - 100 identical tokens, warm | 1.78 µs | 1 miss + 99 hits; 1.6× vs `build_tree` |
| parse_green_recover - no interner, small | 0.62 µs | `x + 1`, no interning |
| parse_green_recover - cold interner, small | 0.87 µs | `x + 1`, first parse |
| parse_green_recover - warm interner, small | 0.70 µs | `x + 1`, subsequent; 1.13× overhead |
| parse_green_recover - no interner, large | 4.95 µs | `λf.λx.if…`, no interning |
| parse_green_recover - warm interner, large | 5.47 µs | `λf.λx.if…`, subsequent; 1.10× overhead |

### Notable Changes vs 2026-02-21

The interner key fix (two-level map) substantially improved all `IncrementalParser` benchmarks
because `IncrementalParser` calls `intern_token` on every token during every parse:

| Metric | 2026-02-21 | 2026-02-23 | Change |
|---|---:|---:|---|
| incremental vs full - edit at start | 8.73 µs | 10.15 µs | +16% (more features) |
| best case - cosmetic change | 2.14 µs | 2.53 µs | +18% (more features) |
| memory pressure - large document | 14.24 µs | 16.53 µs | +16% (more features) |

Incremental numbers are modestly higher than 2026-02-21 because the parser now
maintains a green tree, token buffer, and interner through each edit. The 2026-02-21
snapshot predates green-tree integration.

## 2026-02-21 (JST) / 2026-02-20 (US)

- Command: `moon bench --package dowdiness/parser/benchmarks --release`
- Hash strategy: hybrid (`GreenToken`/`GreenNode` cached structural hash via FNV; `Hash` trait impls for collection interop)
- Environment: local developer machine
- Result: `44/44` benchmarks passed

| Metric | Mean | Notes |
|---|---:|---|
| parse scaling - large (30+ tokens) | 6.50 µs | Full parse baseline (large) |
| incremental vs full - edit at start | 8.73 µs | Boundary edit, root invalidation path |
| incremental vs full - edit in middle | 8.74 µs | Boundary edit, root invalidation path |
| incremental vs full - edit at end | 8.57 µs | Boundary edit, root invalidation path |
| best case - cosmetic change | 2.14 µs | Localized edit path |
| worst case - full invalidation | 8.53 µs | Full rebuild + incremental overhead |
| memory pressure - large document | 14.24 µs | Larger input incremental edit scenario |
| phase1: full tokenize - 110 tokens | 1.16 µs | Tokenization baseline |
| phase1: incremental tokenize - edit at start | 2.04 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit in middle | 1.96 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit at end | 1.89 µs | Includes `TokenBuffer::new()` setup |
| phase1: full re-tokenize after edit | 1.13 µs | Comparison baseline |

### Green-Tree Focused Metrics (from same full run)

| Metric | Mean | Notes |
|---|---:|---|
| green-tree - token constructor | 0.02 µs | `GreenToken::new` hash compute path |
| green-tree - node constructor from 32 children | 0.06 µs | `GreenNode::new` fold/hash path |
| green-tree - equality identical 32 children | 0.17 µs | Hash check + deep equality walk |
| green-tree - equality mismatch hash fast path | 0.01 µs | Expected early hash mismatch exit |

## 2026-02-19

- Command: `moon bench --package dowdiness/parser/benchmarks --release`
- Git ref: `main` (`fc3e44b`)
- Environment: local developer machine
- Result: `40/40` benchmarks passed

| Metric | Mean | Notes |
|---|---:|---|
| parse scaling - small (5 tokens) | 0.87 µs | Full parse baseline (small) |
| parse scaling - medium (15 tokens) | 3.79 µs | Full parse baseline (medium) |
| parse scaling - large (30+ tokens) | 7.04 µs | Full parse baseline (large) |
| incremental vs full - edit at start | 8.95 µs | Boundary edit, root invalidation path |
| incremental vs full - edit in middle | 9.11 µs | Boundary edit, root invalidation path |
| incremental vs full - edit at end | 8.22 µs | Boundary edit, root invalidation path |
| best case - cosmetic change | 2.11 µs | Localized edit path |
| worst case - full invalidation | 8.62 µs | Full rebuild + incremental overhead |
| memory pressure - large document | 14.33 µs | Larger input incremental edit scenario |
| phase1: full tokenize - 110 tokens | 1.16 µs | Tokenization baseline |
| phase1: incremental tokenize - edit at start | 2.04 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit in middle | 1.94 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit at end | 1.88 µs | Includes `TokenBuffer::new()` setup |
| phase1: full re-tokenize after edit | 1.10 µs | Comparison baseline |

### Green-Tree Microbenchmark Snapshot (2026-02-19)

- Command: `moon bench --package dowdiness/parser/benchmarks --release`
- Git ref: `main` (working tree includes `src/benchmarks/green_tree_benchmark.mbt`)
- Result: `44/44` benchmarks passed

| Metric | Mean | Notes |
|---|---:|---|
| green-tree - token constructor | 0.02 µs | `GreenToken::new` hash compute path |
| green-tree - node constructor from 32 children | 0.05 µs | `GreenNode::new` fold/hash path |
| green-tree - equality identical 32 children | 0.16 µs | Hash check + deep equality walk |
| green-tree - equality mismatch hash fast path | 0.01 µs | Expected early hash mismatch exit |

### Green-Tree Focused Run (2026-02-19)

- Context: second run on the focused subset after adding `Hash` impls for `GreenToken`,
  `GreenElement`, `GreenNode` using cached structural hashes. Small differences vs the
  snapshot above are within run-to-run noise.
- Command: `moon bench --package dowdiness/parser/benchmarks --file green_tree_benchmark.mbt --release`
- Result: `4/4` benchmarks passed

| Metric | Mean | Notes |
|---|---:|---|
| green-tree - token constructor | 0.01 µs | `GreenToken::new` hash compute path |
| green-tree - node constructor from 32 children | 0.07 µs | `GreenNode::new` fold/hash path |
| green-tree - equality identical 32 children | 0.17 µs | Hash check + deep equality walk |
| green-tree - equality mismatch hash fast path | 0.01 µs | Expected early hash mismatch exit |

## 2026-02-03

- Command: `moon bench --package parser --release`
- Environment: local developer machine (same repo state as docs update)

| Metric | Mean | Notes |
|---|---:|---|
| parse scaling - large (30+ tokens) | 6.46 µs | Full parse baseline for larger input |
| incremental vs full - edit at start | 11.12 µs | Boundary edit, root invalidation path |
| incremental vs full - edit in middle | 10.74 µs | Boundary edit, root invalidation path |
| incremental vs full - edit at end | 10.95 µs | Boundary edit, root invalidation path |
| best case - cosmetic change | 2.37 µs | Localized edit path |
| worst case - full invalidation | 11.25 µs | Full rebuild + incremental overhead |
| phase1: full tokenize - 110 tokens | 1.23 µs | Tokenization baseline |
| phase1: incremental tokenize - edit at start | 2.12 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit in middle | 2.00 µs | Includes `TokenBuffer::new()` setup |
| phase1: incremental tokenize - edit at end | 1.95 µs | Includes `TokenBuffer::new()` setup |
| phase1: full re-tokenize after edit | 1.28 µs | Comparison baseline |

## Notes

- Incremental token benchmarks currently include setup (`TokenBuffer::new()`).
- Add a setup-free benchmark variant when Step 2 starts to isolate `TokenBuffer.update` cost directly.
